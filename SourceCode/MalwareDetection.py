import os
import sys
from os import walk
import pickle
import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
import csv

vocab = []


def LoadModels():
    with open('staticAnalysis_model', 'rb') as training_model:
        global Staticmodel
        Staticmodel = pickle.load(training_model)

    with open('staticAnalysisStructureInfo_model', 'rb') as training_model:
        global StaticStructuremodel
        StaticStructuremodel = pickle.load(training_model)
    
    # define empty list
    global vocab
    
    # open file and read the content in a list
    with open('vacab.txt', 'r') as filehandle:
        vocab = [current_place.rstrip() for current_place in filehandle.readlines()]


def DynamicAnalysis(file_path):
    with open(file_path) as f:
        datafile = f.readlines()
    for line in datafile:
        if "AntiVirus engines" in line:
            return True
    return False


def StaticAnalysis(file_path):
    X = []
    f = open(file_path, "r", encoding="ISO-8859-1")
    txt = ""
    for line in f:
        line = line.replace("\n", "")
        dot_count = line.count(".")
        if dot_count <= 1 and len(line) > 5:
            if re.match(r'^[a-zA-Z_][0-9a-zA-Z._]*$', line):
                txt += line
                txt += " "
    X.append(txt)
    
    vectorizer = CountVectorizer(vocabulary=vocab)
    X = vectorizer.fit_transform(X).toarray()
    
    y_pred = Staticmodel.predict(X)
    return y_pred

def StaticStructureAnalysis(file_path):
    X = []
    col = []
    f = open(file_path, "r", encoding="ISO-8859-1")
    imgSec_flag = 0
    script_count = 0
    unapt_size_diff = 0
    virtualsize = 0
    rawdatasize = 0
    for line in f:
        if (line.find("\\x")):
            script_count += 1
        if (imgSec_flag == 0 and line.find("IMAGE_SECTION_HEADER") != -1):
            imgSec_flag = 1
            continue
        if (imgSec_flag == 1):
            if (line.find("Misc_VirtualSize") != -1):
                virtualsize = int(line.split(":")[-1], 16)
            if (line.find("SizeOfRawData") != -1):
                rawdatasize = int(line.split(":")[-1], 16)
                if (virtualsize > 2 * rawdatasize):
                    unapt_size_diff += 1
                virtual_size = 0
                rawdatasize = 0
                imgSec_flag = 0
                continue
    col.append(unapt_size_diff)
    col.append(script_count)
    X.append(col)
    y_pred = StaticStructuremodel.predict(X)
    return y_pred

def MalwareAnalysis(filePaths):
    fileHashes = []
    filePred = []
    
    for file in filePaths:
        fileHashes.append(file[0])
        print(file[0])
        pred = 0
        if file[1] != "":
            pred = pred | StaticAnalysis(file[1])

        if file[2] != "":
            pred = pred | StaticStructureAnalysis(file[2])

        if file[3] != "":
            pred = pred | DynamicAnalysis(file[3])
        
        filePred.append(pred)
    
    PredictionArray = []
    for i in range(0, len(fileHashes)):
        PredictionArray.append([fileHashes[i], int(filePred[i])])
    
    with open('output.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerows(PredictionArray)


# def LoadTestDataset(testDataDirPath):
#     fileHashes = {}
#
#     fileStringPath = {}
#     fileStructure_InfoPath = {}
#     fileDynamicPath = {}
#
#     for (dirpath, dirnames, filenames) in walk(testDataDirPath):
#         for file in filenames:
#             if (file == "String.txt"):
#                 fileStringPath[dirpath.split("\\")[-2]] = (dirpath + "\\" + file)
#                 fileHashes[dirpath.split("\\")[-2]] = 1
#             if (file == "Structure_Info.txt"):
#                 fileStructure_InfoPath[dirpath.split("\\")[-2]] = (dirpath + "\\" + file)
#                 fileHashes[dirpath.split("\\")[-2]] = 1
#             if ".json" in file:
#                 fileDynamicPath[file.split(".")[-2]] = (dirpath + "\\" + file)
#                 fileHashes[file.split(".")[-2]] = 1
#
#     filePaths = []
#     for file in fileHashes.keys():
#         col = []
#         col.append(file)
#         if (file in fileStringPath):
#             col.append(fileStringPath[file])
#         else:
#             col.append("")
#
#         if (file in fileStructure_InfoPath):
#             col.append(fileStructure_InfoPath[file])
#         else:
#             col.append("")
#
#         if (file in fileDynamicPath):
#             col.append(fileDynamicPath[file])
#         else:
#             col.append("")
#         filePaths.append(col)
#
#     return filePaths

def LoadData(trainDataDirPath):
    fileHashes = {}
    
    fileStringPath = {}
    fileStructure_InfoPath = {}
    fileDynamicPath = {}
    for (dirpath, dirnames, filenames) in walk(trainDataDirPath):
        for file in filenames:
            if file == "String.txt":
                fileStringPath[dirpath.split("/")[-1]] = (dirpath + "/" + file)
                fileHashes[dirpath.split("/")[-1]] = 1
            if file == "Structure_Info.txt":
                fileStructure_InfoPath[dirpath.split("/")[-1]] = (dirpath + "/" + file)
                fileHashes[dirpath.split("/")[-1]] = 1
            if ".json" in file:
                fileDynamicPath[file.split(".")[-2]] = (dirpath + "/" + file)
                fileHashes[file.split(".")[-2]] = 1
    
    filePaths = []
    for file in fileHashes.keys():
        col = []
        col.append(file)
        if file in fileStringPath:
            col.append(fileStringPath[file])
        else:
            col.append("")
        
        if file in fileStructure_InfoPath:
            col.append(fileStructure_InfoPath[file])
        else:
            col.append("")
        
        if file in fileDynamicPath:
            col.append(fileDynamicPath[file])
        else:
            col.append("")
        filePaths.append(col)
    return filePaths


# Defining main function
def main():
    # total arguments
    n = len(sys.argv)
    if n == 2:
        # Arguments passed
        print("\nFull Path to Test Dataset Directory: ", sys.argv[1])
    elif n > 2:
        print("Extra arguments provided")
    else:
        print("Provide the full path to test dataset directory")
    
    if not os.access(os.path.dirname(sys.argv[1]), os.R_OK):
        print("file does not exists ")
        exit()
    
    # filePaths = LoadTestDataset(sys.argv[1])
    filePaths = LoadData(sys.argv[1])
    # print(filePaths)
    LoadModels()
    MalwareAnalysis(filePaths)


if __name__ == "__main__":
    main()
