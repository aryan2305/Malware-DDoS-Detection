#!/usr/bin/env python
# coding: utf-8

# In[5]:


import numpy as np
import re
import pickle


# In[6]:


from os import walk


# In[7]:



folder_path = "C:\\Users\\Aryan Agrawal\\Desktop\\HackIITK\\Static_Analysis_Data"


fileHashes = []

hashedMalwareFiles = []
for (dirpath, dirnames, filenames) in walk(folder_path+"\\Malware"):
    for file in filenames:
        if(file == "String.txt"):
            hashedMalwareFiles.append(dirpath+"\\"+file)
            fileHashes.append(dirpath.split("\\")[-1])
            

hashedBenignFiles = []
for (dirpath, dirnames, filenames) in walk(folder_path+"\\Benign"):
    for file in filenames:
        if(file == "String.txt"):
            hashedBenignFiles.append(dirpath+"\\"+file)
            fileHashes.append(dirpath.split("\\")[-1])


# In[8]:


X=[]
y=[]
for file in hashedMalwareFiles:
    f = open(file, "r",encoding="ISO-8859-1")
    txt = ""
    for line in f:
        line = line.replace("\n","")
        dot_count = line.count(".")
        if(dot_count<=1 and len(line)>5):
            if(re.match(r'^[a-zA-Z_][0-9a-zA-Z._]*$', line)):
                txt+=line
                txt+=" "
    X.append(txt)
    y.append(1)

for file in hashedBenignFiles:
    f = open(file, "r",encoding="ISO-8859-1")
    txt = ""
    for line in f:
        line = line.replace("\n","")
        dot_count = line.count(".")
        if(dot_count<=1 and len(line)>5):
            if(re.match(r'^[a-zA-Z_][0-9a-zA-Z._]*$', line)):
                txt+=line
    X.append(txt)
    y.append(0)

print(len(X))
print(len(y))
print(X[0],y[0])


# In[9]:


X2 = X[:]
y2 = y[:]


# In[10]:


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, random_state=0)


# In[11]:


from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)
X_train = vectorizer.fit_transform(X_train).toarray()
vocab = vectorizer.get_feature_names()
with open('vacab.txt', 'w') as filehandle:
    filehandle.writelines("%s\n" % keyword for keyword in vocab)


# In[12]:


vectorizer2 = CountVectorizer(vocabulary = vocab)
X_test = vectorizer2.fit_transform(X_test).toarray()


# In[13]:


from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators=1000, random_state=0)
classifier.fit(X_train, y_train) 


# In[14]:


y_pred = classifier.predict(X_test)


# In[15]:


from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))


# In[16]:


with open('staticAnalysis_model', 'wb') as picklefile:
    pickle.dump(classifier,picklefile)


# In[17]:


with open('staticAnalysis_model', 'rb') as training_model:
    model = pickle.load(training_model)


# In[18]:


y_pred2 = model.predict(X_test)

print(confusion_matrix(y_test, y_pred2))
print(classification_report(y_test, y_pred2))
print(accuracy_score(y_test, y_pred2)) 


# In[19]:


print(X_train.shape)
print(X_test.shape)


# In[ ]:




